{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an ANN with Tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNn9bK+bCZBs8SKH6R84TCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fact-h/Tensorflow-ML-tutorial/blob/main/Building_an_ANN_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 人工神经网络简介\n",
        "人工智能包括机器学习，机器学习又包括深度学习，深度学习由若干连续层组成，每一层建立在前一层的输出上，所有层组合形成人工神经网络。数据越多，深度学习的性能越高。"
      ],
      "metadata": {
        "id": "557K9Rg7lCag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 实施\n",
        "受人脑处理信息的生物神经网络启发，深度神经网络的例子如下；![](https://miro.medium.com/max/1392/1*Cdb40X2xA2LFBGehT7jQ1g.png)\n"
      ],
      "metadata": {
        "id": "Q2IJQvAcMCXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 输入层\n",
        "输入层由多个独立变量的输入组成，这些输入可以通过外部的网络或 CSV 文件加载数据。简单来说，这些变量是特征，比如：卧室的数量、房子的面积、到城市的距离，都是在购买房子时需要考虑的特征，我们随机初始化接近0但不是0的权重。\n"
      ],
      "metadata": {
        "id": "l0IDd5gcN0nX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 权重\n",
        "每一个节点（神经元）都有权重。神经网络通过权重学习，通过调整权重，神经网络决定哪些特征重要或不重要。"
      ],
      "metadata": {
        "id": "Ey8kJVEnO8la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 隐藏层\n",
        "在输入层与输出层之间的层，在隐藏层中，神经元获得带权重的输入，通过激活函数产生输出。\n",
        "![](https://developers.google.com/machine-learning/crash-course/images/activation.svg?hl=zh-cn)\n",
        "**Step 1：**输入值和权值相乘，加上偏差，加到一块。\n",
        "\n",
        "**Step 2：**引入激活函数(非线性函数)，激活函数将非线性引入到神经网络中,使神经网络能够处理输入和输出之间的非线性关系，建立非常复杂的模型。常见的激活函数有 Sigmoid, ReLU.\n",
        "\n",
        "**Step 3：**数据通过所有隐藏层，传递到输出层。"
      ],
      "metadata": {
        "id": "D3bsNj12QYwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 输出层\n",
        "神经网络的最后一个层，从隐藏层的最后一个节点获得输入。输出层可以是：\n",
        "\n",
        "- 连续值（股票价格）\n",
        "- 二值（0或1）\n",
        "- 分类（猫或狗或鸭子）"
      ],
      "metadata": {
        "id": "bIB3-TM_XP1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 神经网络如何工作\n",
        "神经网络的学习过程可以看作 pass 和 return 的迭代过程。Pass 是信息前向传播（Forward Propagation of Information），return 是信息反向传播（Backward Propagation of Information）。![](https://miro.medium.com/max/1256/1*Kw7xfwaK2hzGR3stRth-7A.png)\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*LvAEM6b992X9JBWVDBaqlQ.jpeg)\n",
        "\n",
        "在前向传播中，给定一些数据，计算带有权值的输入值的点乘，加在一起，在隐藏层应用于激活函数的结果。\n",
        "\n",
        "激活函数将非线性引入到网络中，所以网络能简单的映射数据。这个节点对下一层来说是输入层，该过程一直重复直到得到最终的输出向量 𝒚，即神经网络的预测值。\n",
        "\n",
        "为了知道模型性能如何，我们将预测值于真实值比较，得到的差值即误差，称为代价函数（Cost Function）或损失函数（Loss Function）。损失函数是权重和偏差的函数。\n",
        "\n",
        "损失函数越小，模型准确性越高，我们的目标是最小化损失函数，损失函数的公式可以是：\n",
        "\n",
        "$C=\\frac12(\\hat{y}-y)^2$\n",
        "\n",
        "计算完损失函数后，我们将信息反馈给神经网络，通过权重传回，并**按减小损失函数的方向调整权重**，这个过程称为**反向传播**。重复几次该过程，最终得到最小化损失函数的预测值。\n"
      ],
      "metadata": {
        "id": "8JKed5G8Xzhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 梯度下降\n",
        "一种通过最小化损失函数改进神经网络模型的优化技术。梯度下降过程发生在反向传播过程，为达到全局最小值调整特征的权重。\n",
        "一些梯度下降算法：\n",
        "- **全批量梯度下降(full-Batch Gradient Descent)**，每次迭代计算整个数据集的损失函数和梯度，如果数据集很大，迭代时间会很长。\n",
        "- **随机梯度下降(Stochastic gradient descent a.k.a. SGD)**，batch大小为1，即每次迭代只选一个样本，只要迭代次数足够，SGD能够工作但过程很曲折。\n",
        "- **最小批次梯度下降(Mini-batch stochastic gradient descent)**，对于大型数据集，一次计算所有样本的损失函数耗时太长，所以每次选取一部分样本（比如一次选100个样本）计算损失函数，并沿梯度方向调整权重。\n",
        "\n",
        "Mini-batch是full-batch和SGD的折中方案，每次迭代通常随机选取10到1000个样本，比full-batch效率更高，过程比SGD更顺畅"
      ],
      "metadata": {
        "id": "BFmkmCGzeYeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 总结\n",
        "- 需要随机初始化权重，接近零但不是零。\n",
        "- 给输入层提供数据\n",
        "- 正向传播，向输出层传播。\n",
        "- 使用损失函数比较真实值和预测值，误差值反馈到神经网络。\n",
        "- 反向传播发生在误差值反馈阶段，沿损失函数的梯度方向调整权重，以获得更小的损失函数。\n",
        "- 对数据集中所有的数据重复上述步骤（full-batch），或一个批次一个批次的迭代（SGD或Mini-batch）\n",
        "- 当将整个数据集传过神经网络，称为一个epoch，比如5个epoch即过5遍整个数据集"
      ],
      "metadata": {
        "id": "FQm5xv3BfeM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立一个人工神经网络识别图像的类别"
      ],
      "metadata": {
        "id": "4lema6hEogBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导入所有的tensorflow库和数据集"
      ],
      "metadata": {
        "id": "m1bEq1zyqzln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_QbOu2HMk3Rz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据预处理\n",
        "### 载入数据集\n",
        "使用 **`load_data()`** 载入Fashion mnist数据集"
      ],
      "metadata": {
        "id": "Oa51EJodrWPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUdQmCqPrqYB",
        "outputId": "fdd52816-e10b-407f-ee20-ea7554cccf95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 归一化\n",
        "像素值在0到255之间，将每个像素值除以255，使其值范围在0到1之间，这样训练速度更快。"
      ],
      "metadata": {
        "id": "Nbq1CnsDuWUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "-sSI0GQX-lgw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 重塑数据形状（Reshaping）\n",
        "我们会得到一个二维矩阵作为输出，第一维对应图像的索引，第二维是包含图像所有像素的向量。\n",
        "\n",
        "使用数据的**`reshape`**方法重塑数据形状，将二维矩阵转换为一维向量，此处传递两个参数：\n",
        "- -1 → 重塑所有图像\n",
        "- 28*28 → 结果向量的大小（784个像素 → 一维）"
      ],
      "metadata": {
        "id": "ucNtYw0B--T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1,28*28)\n",
        "X_test = X_test.reshape(-1,28*28)"
      ],
      "metadata": {
        "id": "mQhxCszvNJiA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立ANN\n",
        "在建立一个模型前，我们首先要创建一个模型对象，这个对象是**`Sequential`**类的一个实例。\n",
        "\n",
        "keras有两种方法建立模型\n",
        "- 一种是对**`tf.keras.Model`**类进行扩展以定义自己的新模型，同时手工编写训练和评估模型的流程。此方式灵活度高，且于其他深度学习框架（Pytorch, Chainer）共通。\n",
        "- 不过很多时候，我们只需要建立一个结构相对简单和典型的神经网络（比如MLP和CNN），并使用常规手段训练。keras提供了一种更简单高效的内置方法来建立、训练和评估模型。\n",
        "- 最典型和常用的神经网络结构是将一堆层按特定顺序叠加起来，所以，我们只需要提供一个层的列表，就能由keras将它们自动首尾相连，形成模型。keras的Sequential API正是如此，通过**`tf.keras.models.Sequential()`**提供一个层的列表，就能快速建立一个模型"
      ],
      "metadata": {
        "id": "tuXA22m4NhMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "oh0zkvyOOQln"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 添加第一个全连接层\n",
        "超参数：\n",
        "- 神经元数量：128\n",
        "- 激活函数：ReLU\n",
        "- 输入形状(input_shape)：(784, )\n",
        "\n",
        "意思是这个层有128个神经元，应用 ReLU 激活函数，引入非线性，输入形状为(784, )。使用**`model.add()`**方法添加这些超参数。"
      ],
      "metadata": {
        "id": "r1s-sQDGSzQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784,)))"
      ],
      "metadata": {
        "id": "tE8XjA9uVOXk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 添加一个Dropout层\n",
        "随机设置一个层的神经元为0的正则化技术，这样一来，在整个训练过程中，一定比例的神经元不会更新，能够减少过拟合的发生。"
      ],
      "metadata": {
        "id": "vVyJs_7LWf8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "S6I_8bT5XMYQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 添加输出层\n",
        "- units = 要分类的类别数量（在本例中为10）\n",
        "- activation = softmax(返回该类的概率)"
      ],
      "metadata": {
        "id": "TwXbAmo6XZrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "BxXySMCQXxxL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 配置模型\n",
        "**`tf.keras.model.compile`**接受3个重要参数\n",
        "- **optimizer**：优化器\n",
        "- **loss**：损失函数\n",
        "- **metrics**：评估指标"
      ],
      "metadata": {
        "id": "POIkAyynYFrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "id": "evsaaIHYZqfO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 训练模型\n",
        "使用**`model.fit()`**方法训练模型，该方法接受5个重要参数：\n",
        "- **x**：训练数据的特征，X_train\n",
        "- **y**：训练数据的标签，y_train\n",
        "- **epochs**：将训练数据迭代多少遍\n",
        "- **batch_size**：批次的大小\n",
        "- **vallidation_split**：分出一定比例的训练数据作为验证数据"
      ],
      "metadata": {
        "id": "a7lGgfp7bIzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axN5A5wWd8bf",
        "outputId": "f05dae8f-5e7d-4804-9940-b794b4fd3720"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.8087\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8534\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3718 - sparse_categorical_accuracy: 0.8650\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.8732\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3342 - sparse_categorical_accuracy: 0.8776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9c9d673210>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 评估模型\n",
        "用测试集评估模型的性能，需提供两个参数：测试数据特征和标签。\n",
        "\n",
        "这里返回两个参数，一个是在测试集中预测的损失，另一个是准确度"
      ],
      "metadata": {
        "id": "A3AzJ2zDeKiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_accuracy = model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87LxjDwee8HT",
        "outputId": "6a2273ad-3dd3-497b-b0b5-eb2b48097228"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3567 - sparse_categorical_accuracy: 0.8703\n"
          ]
        }
      ]
    }
  ]
}